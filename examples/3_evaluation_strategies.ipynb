{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining an evaluation strategies for an AI application\n",
    "\n",
    "Often times, we want to evaluate an AI application based on multiple metrics. We can create as many metrics as we want, and then define an evaluation strategy that aggregates them.\n",
    "\n",
    "In this tutorial, we will learn how to create an multi-dimensional error detection strategy utilizing different judges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application\n",
    "\n",
    "We want to evaluate an AI application that helps journalists generate articles.\n",
    "\n",
    "The user provides instructions for the article, that can include context, and the application generates an article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample data\n",
    "\n",
    "For illustration purposes, we will use only 2 articles synthetically generated by an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "context = \"\"\"GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models\n",
    "Tyna Eloundou, Sam Manning, Pamela Mishkin, Daniel Rock\n",
    "We investigate the potential implications of large language models (LLMs), such as Generative Pre-trained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classifications. Our findings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs. The projected effects span all wage levels, with higher-income jobs potentially facing greater exposure to LLM capabilities and LLM-powered software. Significantly, these impacts are not restricted to industries with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15% of all worker tasks in the US could be completed significantly faster at the same level of quality. When incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56% of all tasks. This finding implies that LLM-powered software will have a substantial effect on scaling the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of general-purpose technologies, indicating that they could have considerable economic, social, and policy implications.\n",
    "\n",
    "Our study is motivated less by the progress of these models alone though, and more by the breadth,\n",
    "scale, and capabilities we’ve seen in the complementary technologies developed around them. The role of\n",
    "complementary technologies remains to be seen, but maximizing the impact of LLMs appears contingent\n",
    "on integrating them with larger systems (Bresnahan, 2019; Agrawal et al., 2021). While the focus of our\n",
    "discussion is primarily on the generative capabilities of LLMs, it is important to note that these models can\n",
    "also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\n",
    "for custom search applications, and LLMs can perform tasks such as summarization and classification where\n",
    "the context may be largely contained in the prompt.\n",
    "To complement predictions of technology’s impacts on work and provide a framework for understanding\n",
    "the evolving landscape of language models and their associated technologies, we propose a new rubric\n",
    "for assessing LLM capabilities and their potential effects on jobs. This rubric (A.1) measures the overall\n",
    "exposure of tasks to LLMs, following the spirit of prior work on quantifying exposure to machine learning\n",
    "(Brynjolfsson et al., 2018; Felten et al., 2018; Webb, 2020). We define exposure as a proxy for potential\n",
    "economic impact without distinguishing between labor-augmenting or labor-displacing effects. We employ\n",
    "human annotators and GPT-4 itself as a classifier to apply this rubric to occupational data in the U.S. economy,\n",
    "primarily sourced from the O*NET database.1 2\n",
    "To construct our primary exposure dataset, we collected both human annotations and GPT-4 classifications,\n",
    "using a prompt tuned for agreement with a sample of labels from the authors. We observe similar agreement\n",
    "\n",
    "In conclusion, this study offers an examination of the potential impact of LLMs on various occupations and\n",
    "industries within the U.S. economy. By applying a new rubric for understanding LLM capabilities and their\n",
    "potential effects on jobs, we have observed that most occupations exhibit some degree of exposure to LLMs,\n",
    "with higher-wage occupations generally presenting more tasks with high exposure. Our analysis indicates that\n",
    "approximately 19% of jobs have at least 50% of their tasks exposed to LLMs when considering both current\n",
    "model capabilities and anticipated LLM-powered software.\n",
    "Our research aims to highlight the general-purpose potential of LLMs and their possible implications for\n",
    "US workers. Previous literature demonstrates the impressive improvements of LLMs to date (see 2.1). Our\n",
    "findings confirm the hypothesis that these technologies can have pervasive impacts across a wide swath of\n",
    "occupations in the US, and that additional advancements supported by LLMs, mainly through software and\n",
    "digital tools, can have significant effects on a range of economic activities. However, while the technical\n",
    "capacity for LLMs to make human labor more efficient appears evident, it is important to recognize that social,\n",
    "economic, regulatory, and other factors will influence actual labor productivity outcomes. As capabilities\n",
    "continue to evolve, the impact of LLMs on the economy will likely persist and increase, posing challenges for\n",
    "policymakers in predicting and regulating their trajectory.\n",
    "Further research is necessary to explore the broader implications of LLM advancements, including\n",
    "their potential to augment or displace human labor, their impact on job quality, impacts on inequality, skill\n",
    "development, and numerous other outcomes. By seeking to understand the capabilities and potential effect\"\"\"\n",
    "\n",
    "user_instructions = \"\"\"AI is here to stay and we need to understand how AI is gonna impact the job market.\n",
    "\n",
    "Use the information in the context to write a comprehensive article.\n",
    "\n",
    "Please provide clear paragraph separation.\"\"\"\n",
    "\n",
    "article_1 = \"\"\"# AI's Impact on the Job Market: A Comprehensive Look at Large Language Models\n",
    "\n",
    "Artificial Intelligence (AI) is no longer a futuristic concept; it's here, and its impact on the job market is becoming increasingly apparent. A recent study by researchers Tyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel Rock sheds light on how large language models (LLMs), such as GPT-4, could potentially reshape the U.S. labor landscape.\n",
    "\n",
    "## The Widespread Impact of AI on Jobs\n",
    "\n",
    "The study reveals a startling statistic: approximately 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of LLMs. Even more striking, about 19% of workers may see at least 50% of their tasks impacted. This suggests that AI's influence on the job market is not limited to a few sectors but could have far-reaching consequences across various industries.\n",
    "\n",
    "## Higher-Income Jobs at Greater Risk\n",
    "\n",
    "Contrary to popular belief, it's not just low-wage jobs that are vulnerable to AI disruption. The research indicates that higher-income jobs potentially face greater exposure to LLM capabilities and LLM-powered software. This finding challenges the notion that AI will primarily affect routine, low-skill tasks and suggests a more complex transformation of the labor market.\n",
    "\n",
    "## The Power of LLM-Powered Software\n",
    "\n",
    "While LLMs alone are impressive, the study emphasizes the potential of software and tools built on top of these models. With access to an LLM, about 15% of all worker tasks in the U.S. could be completed significantly faster at the same level of quality. However, when incorporating LLM-powered software, this share increases dramatically to between 47 and 56% of all tasks. This highlights the importance of considering not just the AI models themselves, but also the ecosystem of tools and applications that leverage their capabilities.\n",
    "\n",
    "## AI as a General-Purpose Technology\n",
    "\n",
    "The researchers conclude that LLMs such as GPTs exhibit traits of general-purpose technologies, indicating that they could have considerable economic, social, and policy implications. This classification puts AI in the same category as other transformative technologies like electricity or the internet, suggesting its potential to reshape multiple sectors of the economy.\n",
    "\n",
    "## The Need for Further Research and Policy Considerations\n",
    "\n",
    "While the study provides valuable insights into AI's potential impact on the job market, it also highlights the need for further research. The authors stress the importance of exploring the broader implications of LLM advancements, including their potential to augment or displace human labor, impact job quality, influence inequality, and affect skill development.\n",
    "\n",
    "As AI continues to evolve and integrate into various aspects of work, policymakers face the challenge of predicting and regulating its trajectory. The pervasive nature of AI's potential impact underscores the need for proactive policies that can help workers and industries adapt to this technological shift.\n",
    "\n",
    "In conclusion, AI is indeed here to stay, and its impact on the job market is likely to be profound and wide-ranging. As we navigate this new landscape, it's crucial for workers, employers, and policymakers to stay informed and adaptable, ready to harness the potential of AI while mitigating its potential disruptions to the workforce.\"\"\"\n",
    "article_2 =\"\"\"# Artificial Intelligence Might Change Everything About Jobs, New Study Claims\n",
    "\n",
    "In a world where technology seems to be taking over everything, a new study has come out that's got everyone talking. It's all about how artificial intelligence, or AI for short, could shake up the job market in a big way. The study, done by some researchers with really long names, looks at something called \"large language models\" or LLMs. These are like super smart computer programs that can understand and write text, kind of like a robot writer.\n",
    "\n",
    "So, these researchers say that these LLMs could affect a whopping 80% of workers in the United States. That's a lot of people! They think that for most of these workers, at least 10% of what they do at work could be changed by AI. And for some people, it could be even more - like half of their job tasks! Can you imagine that? It's like having a robot colleague that can do half your work.\n",
    "\n",
    "But here's the really weird part - it's not just the simple jobs that might be affected. The study says that people with high-paying jobs might actually be more at risk. That's pretty surprising, right? You'd think it would be the other way around. I guess even the bosses aren't safe from the robot invasion!\n",
    "\n",
    "The researchers also talked about something called \"LLM-powered software.\" Basically, that's when you take these smart AI programs and use them to make other computer programs. They say this could make an even bigger difference. With this kind of software, almost half of all the tasks people do at work could be done faster or better. That's a lot of change!\n",
    "\n",
    "Now, the study doesn't say exactly when all this is going to happen. It's not like we're going to wake up tomorrow and find robots sitting at our desks. But it does seem like it could be a big deal in the future. The researchers think AI could be as important as electricity was when it was invented. Remember learning about that in history class? It changed everything!\n",
    "\n",
    "Of course, not everyone agrees about how big a deal this is going to be. Some people think the researchers are exaggerating, and that AI won't really change that much. Others are worried that it could lead to a lot of people losing their jobs. It's hard to know who's right.\n",
    "\n",
    "The study also talks about how AI might affect different industries. But to be honest, it gets pretty complicated and boring at that point. There's a lot of technical stuff about \"productivity growth\" and \"economic implications\" that I didn't really understand. I guess that's why these researchers get paid the big bucks!\n",
    "\n",
    "In the end, the main takeaway seems to be that AI is coming, and it's going to change things. Whether that's good or bad probably depends on your job and how well you can adapt to working with robot helpers. Maybe it's time to start being extra nice to your computer, just in case!\n",
    "\n",
    "The researchers say we need to do more studies to really understand what's going to happen. They want to look at things like how AI might make some jobs better or worse, and how it might affect inequality. That sounds like a lot more work for them!\n",
    "\n",
    "So, there you have it. AI is coming for our jobs, maybe. Or maybe not. It's all very exciting and confusing at the same time. I guess we'll just have to wait and see what happens. In the meantime, maybe we should all start learning how to program these AI things. You know, just in case.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation criteria and rubrics\n",
    "\n",
    "We want to evaluate the articles based on the following criteria:\n",
    "\n",
    "| Evaluation | Explanation |\n",
    "|------------|-------------|\n",
    "| Completeness | Does the article provide comprehensive coverage of the topics and information the instructions provided, addressing all relevant aspects and key points? |\n",
    "| Clarity | Is the article written in a clear, concise, and easily understandable manner? |\n",
    "| Source Attribution | Does the article properly attribute information to reliable sources provided in the information and the instructions? |\n",
    "| Objectivity | Does the article present information in an unbiased manner, considering multiple perspectives? |\n",
    "\n",
    "These metric are a measure of the quality of the generated article.\n",
    "\n",
    "Since we want to create a multi-dimensional error detection system, we are going to create rubrics in a Pass / Fail scoring scale.\n",
    "\n",
    "Let's create the custom rubrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_judge.metrics import CustomMetric, RubricItem\n",
    "\n",
    "# for all the metrics\n",
    "required_inputs = [\"user_instructions\", \"context\"]\n",
    "required_output = \"article\"\n",
    "\n",
    "completeness_criteria = \"Evaluate the extent to which the article provides comprehensive coverage of all topics, key points, and information specified in the instructions, ensuring that no relevant aspects are omitted or inadequately addressed.\"\n",
    "completeness_rubric = [\n",
    "    RubricItem(\n",
    "        score=0,\n",
    "        description=\"The article fails to provide comprehensive coverage of the required topics, key points, and information specified in the instructions. It omits crucial information and has significant gaps in addressing relevant aspects.\"\n",
    "    ),\n",
    "    RubricItem(\n",
    "        score=1,\n",
    "        description=\"The article offers comprehensive coverage of all required topics, key points, and information specified in the instructions. It thoroughly addresses all relevant aspects, providing in-depth information and leaving no significant gaps in coverage.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "COMPLETENESS_METRIC = CustomMetric(\n",
    "    name=\"completeness\",\n",
    "    criteria=completeness_criteria,\n",
    "    rubric=completeness_rubric,\n",
    "    required_inputs=required_inputs,\n",
    "    required_output=required_output\n",
    ")\n",
    "\n",
    "clarity_criteria = \"Does the article's writing quality in terms of clarity, conciseness, and ease of understanding communicate effectively the information to the reader?\"\n",
    "clarity_rubric = [\n",
    "    RubricItem(\n",
    "        score=0,\n",
    "        description=\"The article's writing quality is poor to moderate in terms of clarity, conciseness, and ease of understanding. It may have confusing sentence structures, inappropriate vocabulary, lack of organization, or instances of unnecessary verbosity. The writing does not effectively communicate the information to the reader, making it difficult to comprehend the content without significant effort.\"\n",
    "    ),\n",
    "    RubricItem(\n",
    "        score=1,\n",
    "        description=\"The article's writing quality is high in terms of clarity, conciseness, and ease of understanding. It features well-constructed sentences, appropriate vocabulary, logical organization, and efficient conveyance of information. The writing effectively communicates the information to the reader, allowing for easy comprehension and a smooth reading experience.\"\n",
    "    )\n",
    "]\n",
    "CLARITY_METRIC = CustomMetric(\n",
    "    name=\"clarity\",\n",
    "    criteria=clarity_criteria,\n",
    "    rubric=clarity_rubric,\n",
    "    required_inputs=required_inputs,\n",
    "    required_output=required_output\n",
    ")\n",
    "\n",
    "source_attribution_criteria = \"Does the article accurately and comprehensively attribute information to reliable sources, ensuring that these sources align with those provided in the information and instructions?\"\n",
    "source_attribution_rubric = [\n",
    "    RubricItem(\n",
    "        score=0,\n",
    "        description=\"The article fails to accurately and comprehensively attribute information to reliable sources. There are significant gaps or inaccuracies in attribution, and many sources either do not align with those provided in the instructions or are unreliable. Attribution practices are inconsistent or inadequate, with key information often lacking proper sourcing.\"\n",
    "    ),\n",
    "    RubricItem(\n",
    "        score=1,\n",
    "        description=\"The article accurately and comprehensively attributes information to reliable sources that align with those provided in the information and instructions. Attribution practices are consistently followed throughout the article, with all key information properly sourced and credited. The sourcing is appropriate and demonstrates excellent adherence to attribution standards.\"\n",
    "    )\n",
    "]\n",
    "SOURCE_ATTRIBUTION_METRIC = CustomMetric(\n",
    "    name=\"source_attribution\",\n",
    "    criteria=source_attribution_criteria,\n",
    "    rubric=source_attribution_rubric,\n",
    "    required_inputs=required_inputs,\n",
    "    required_output=required_output\n",
    ")\n",
    "\n",
    "objectivity_criteria = \"Evaluate whether the article presents information in an unbiased manner by incorporating multiple perspectives fairly and avoiding partisan or one-sided reporting.\"\n",
    "objectivity_rubric = [\n",
    "    RubricItem(\n",
    "        score=0,\n",
    "        description=\"The article shows significant bias in its reporting. It either presents only one perspective or heavily favors a particular viewpoint. Alternative views are absent, minimized, or unfairly represented. The language used may be loaded or emotionally charged, and sources may be limited to those supporting a single perspective. The overall presentation lacks journalistic objectivity and balance.\"\n",
    "    ),\n",
    "    RubricItem(\n",
    "        score=1,\n",
    "        description=\"The article demonstrates a commitment to unbiased reporting. It presents multiple perspectives on the topic, giving fair representation to different viewpoints. The language used is neutral and objective, avoiding loaded terms or emotional rhetoric. The article uses a diverse range of credible sources to support various perspectives. While minor imperfections may exist, the overall presentation maintains journalistic integrity, balance, and objectivity.\"\n",
    "    )\n",
    "]\n",
    "OBJECTIVITY_METRIC = CustomMetric(\n",
    "    name=\"objectivity\",\n",
    "    criteria=objectivity_criteria,\n",
    "    rubric=objectivity_rubric,\n",
    "    required_inputs=required_inputs,\n",
    "    required_output=required_output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom FlowJudge's\n",
    "\n",
    "We can now easily create a model and the different judges to build our multi-dimensional error detection system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_judge import Vllm, EvalInput, FlowJudge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-08 08:53:51 awq_marlin.py:90] The model is convertible to awq_marlin during runtime. Using awq_marlin kernel.\n",
      "WARNING 10-08 08:53:51 config.py:389] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 10-08 08:53:51 llm_engine.py:226] Initializing an LLM engine (v0.6.1.dev238+ge2c6e0a82) with config: model='flowaicom/Flow-Judge-v0.1-AWQ', speculative_config=None, tokenizer='flowaicom/Flow-Judge-v0.1-AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq_marlin, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=flowaicom/Flow-Judge-v0.1-AWQ, use_v2_block_manager=False, num_scheduler_steps=1, multi_step_stream_outputs=False, enable_prefix_caching=False, use_async_output_proc=False, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "INFO 10-08 08:53:52 model_runner.py:1014] Starting to load model flowaicom/Flow-Judge-v0.1-AWQ...\n",
      "INFO 10-08 08:53:52 weight_utils.py:242] Using model weights format ['*.safetensors']\n",
      "INFO 10-08 08:53:53 weight_utils.py:287] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7d4c65f0024b3b9a739d4d63ded733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-08 08:53:53 model_runner.py:1025] Loading model weights took 2.1717 GB\n",
      "INFO 10-08 08:53:55 gpu_executor.py:122] # GPU blocks: 3081, # CPU blocks: 682\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If you are running on an Ampere GPU or newer, create a model using VLLM\n",
    "model = Vllm()\n",
    "\n",
    "# Or if not running on Ampere GPU or newer, create a model using no flash attn and Hugging Face Transformers\n",
    "# model = Hf(flash_attn=False)\n",
    "\n",
    "# Or create a model using Llamafile if not running an Nvidia GPU & running a Silicon MacOS for example\n",
    "# model = Llamafile()\n",
    "\n",
    "# Or create a model using Baseten if you don't want to run locally.\n",
    "# As a pre-requisite step:\n",
    "#  - Sign up to Baseten\n",
    "#  - Generate an api key https://app.baseten.co/settings/api_keys\n",
    "#  - Set the api key as an environment variable & initialize:\n",
    "# import os\n",
    "# os.environ[\"BASETEN_API_KEY\"] = \"your_api_key\"\n",
    "# model = Baseten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create judges\n",
    "completeness_judge = FlowJudge(\n",
    "    metric=COMPLETENESS_METRIC,\n",
    "    model=model\n",
    ")\n",
    "clarity_judge = FlowJudge(\n",
    "    metric=CLARITY_METRIC,\n",
    "    model=model\n",
    ")\n",
    "source_attribution_judge = FlowJudge(\n",
    "    metric=SOURCE_ATTRIBUTION_METRIC,\n",
    "    model=model\n",
    ")\n",
    "objectivity_judge = FlowJudge(\n",
    "    metric=OBJECTIVITY_METRIC,\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of inputs and outputs\n",
    "inputs_batch = [\n",
    "    [\n",
    "        {\"user_instructions\": user_instructions},\n",
    "        {\"context\": context}\n",
    "    ],\n",
    "    [\n",
    "        {\"user_instructions\": user_instructions},\n",
    "        {\"context\": context}\n",
    "    ]\n",
    "]\n",
    "outputs_batch = [\n",
    "    {\"article\": article_1},\n",
    "    {\"article\": article_2}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 2/2 [00:09<00:00,  4.91s/it, est. speed input: 567.04 toks/s, output: 60.98 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:07<00:00,  3.82s/it, est. speed input: 742.59 toks/s, output: 81.80 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:06<00:00,  3.39s/it, est. speed input: 833.66 toks/s, output: 70.87 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:07<00:00,  3.78s/it, est. speed input: 757.42 toks/s, output: 80.35 toks/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of EvalInput\n",
    "eval_inputs_batch = [EvalInput(inputs=inputs, output=output) for inputs, output in zip(inputs_batch, outputs_batch)]\n",
    "\n",
    "# Run batch evaluations for all judges\n",
    "completeness_results = completeness_judge.batch_evaluate(eval_inputs_batch, save_results=False)\n",
    "clarity_results = clarity_judge.batch_evaluate(eval_inputs_batch, save_results=False)\n",
    "source_attribution_results = source_attribution_judge.batch_evaluate(eval_inputs_batch, save_results=False)\n",
    "objectivity_results = objectivity_judge.batch_evaluate(eval_inputs_batch, save_results=False)\n",
    "\n",
    "# Combine results\n",
    "all_results = {\n",
    "    \"completeness\": completeness_results,\n",
    "    \"clarity\": clarity_results,\n",
    "    \"source_attribution\": source_attribution_results,\n",
    "    \"objectivity\": objectivity_results\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Article 1\n",
       "\n",
       "| Metric | Score |\n",
       "|--------|-------|\n",
       "| completeness | 1 |\n",
       "| clarity | 1 |\n",
       "| source_attribution | 1 |\n",
       "| objectivity | 1 |\n",
       "\n",
       "### Feedback\n",
       "\n",
       "**Completeness**: The article provides comprehensive coverage of the key points and information specified in the instructions. It addresses the impact of large language models (LLMs) on the job market, including the potential effects on various occupations and industries within the U.S. economy. The article covers the widespread impact of AI on jobs, the specific risks to higher-income jobs, the power of LLM-powered software, and the classification of LLMs as general-purpose technologies. Additionally, it highlights the need for further research and policy considerations, addressing the broader implications of LLM advancements. The article thoroughly addresses all relevant aspects, providing in-depth information and leaving no significant gaps in coverage.\n",
       "\n",
       "**Clarity**: The article's writing quality is high in terms of clarity, conciseness, and ease of understanding. It effectively communicates the information about AI's impact on the job market, making it easy for readers to comprehend the content.\n",
       "\n",
       "The article is well-structured, with clear paragraph separation and logical flow. It begins with an introduction that sets the context, followed by sections that delve into specific aspects of AI's impact on jobs. Each section is concise and focuses on a single main point, making the information easy to digest.\n",
       "\n",
       "The writing style is clear and straightforward, avoiding unnecessary verbosity. Complex ideas are explained in an accessible manner, using appropriate vocabulary without being overly technical. The article effectively uses headings and subheadings to organize information and guide the reader through the content.\n",
       "\n",
       "The information is conveyed efficiently, with each paragraph building on the previous one to develop a comprehensive understanding of AI's impact on the job market. The use of statistics and specific examples, such as the 80% of the U.S. workforce potentially affected by LLMs, adds credibility and clarity to the arguments presented.\n",
       "\n",
       "Overall, the writing quality of the article is exemplary in terms of clarity, conciseness, and ease of understanding. It effectively communicates the information to the reader, allowing for easy comprehension and a smooth reading experience.\n",
       "\n",
       "**Source_attribution**: The article accurately and comprehensively attributes information to reliable sources that align with those provided in the instructions. The researchers Tyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel Rock are correctly credited for their study on the impact of large language models (LLMs) on the job market. The article also references the GPT-4 model, which is consistent with the context provided. The attribution practices are consistently followed throughout the article, with all key information properly sourced and credited. This demonstrates excellent adherence to attribution standards.\n",
       "\n",
       "However, the article could have provided more specific citations for some of the statistics and claims made, such as the exact sources for the percentages mentioned (e.g., \"approximately 80% of the U.S. workforce could have at least 10% of their work tasks affected\"). While the overall attribution is strong, the lack of specific citations for some data points slightly reduces the comprehensiveness of the attribution.\n",
       "\n",
       "Overall, the article meets the criteria for a \"Yes\" score, as it accurately and comprehensively attributes information to reliable sources that align with those provided in the instructions, with only minor areas for improvement.\n",
       "\n",
       "**Objectivity**: The article presents information in an unbiased manner by incorporating multiple perspectives fairly and avoiding partisan or one-sided reporting. It discusses the potential impact of large language models (LLMs) on the job market from various angles, including the widespread impact on jobs, the specific risks to higher-income jobs, and the power of LLM-powered software. The article also considers the broader implications of LLM advancements, such as their potential to augment or displace human labor, impact job quality, influence inequality, and affect skill development.\n",
       "\n",
       "The language used is neutral and objective, avoiding loaded terms or emotional rhetoric. The article uses a diverse range of credible sources to support various perspectives, including the research by Tyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel Rock, as well as other relevant studies and literature.\n",
       "\n",
       "While the article is comprehensive and well-balanced, it could benefit from including more alternative viewpoints or potential solutions to the challenges posed by AI in the job market. However, overall, the article demonstrates a strong commitment to unbiased reporting and maintains journalistic integrity and balance.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Article 2\n",
       "\n",
       "| Metric | Score |\n",
       "|--------|-------|\n",
       "| completeness | 0 |\n",
       "| clarity | 1 |\n",
       "| source_attribution | 0 |\n",
       "| objectivity | 0 |\n",
       "\n",
       "### Feedback\n",
       "\n",
       "**Completeness**: The article provides a general overview of the potential impact of large language models (LLMs) on the job market, but falls short of comprehensive coverage of all required topics and key points specified in the instructions. While it touches on some important aspects, such as the percentage of workers potentially affected and the distinction between high- and low-wage jobs, it omits several crucial elements.\n",
       "\n",
       "The article fails to adequately address the following key points:\n",
       "\n",
       "1. The specific capabilities of LLMs and how they relate to job tasks\n",
       "2. The proposed rubric for assessing LLM capabilities and their potential effects on jobs\n",
       "3. The distinction between labor-augmenting and labor-displacing effects of LLMs\n",
       "4. The potential for LLMs to augment rather than replace human labor\n",
       "5. The broader economic, social, and policy implications of LLMs\n",
       "6. The need for further research on the impact of LLMs on job quality, inequality, and skill development\n",
       "\n",
       "Additionally, the article oversimplifies complex concepts and fails to provide in-depth information on several aspects. For example, it doesn't explain how LLM-powered software can make tasks faster or better, or how this relates to the rubric proposed in the study.\n",
       "\n",
       "While the article does a good job of making the content accessible to a general audience, it lacks the depth and specificity required for comprehensive coverage of the topic. It also introduces some inaccuracies and speculative statements, such as the claim that \"people with high-paying jobs might actually be more at risk,\" which is not explicitly stated in the original context.\n",
       "\n",
       "Overall, while the article provides a good starting point for understanding the potential impact of LLMs on jobs, it falls short of providing comprehensive coverage of all required topics and key points specified in the instructions.\n",
       "\n",
       "**Clarity**: The article's writing quality is generally clear and easy to understand, but it falls short in terms of conciseness and some aspects of clarity. The content is well-structured and covers the main points from the context provided, making it accessible to a broad audience.\n",
       "\n",
       "The writing is generally clear, with well-constructed sentences and appropriate vocabulary for the topic. For example, the explanation of LLMs and their potential impact on the job market is straightforward and easy to follow.\n",
       "\n",
       "However, the article lacks conciseness in several places. Phrases like \"It's all very exciting and confusing at the same time\" and \"Maybe we should all start learning how to program these AI things\" could be more succinctly expressed. Additionally, some sentences are unnecessarily verbose, such as \"The researchers say we need to do more studies to really understand what's going to happen.\"\n",
       "\n",
       "While the article effectively communicates the main points, it occasionally strays into areas that could have been more concisely addressed, such as the potential need for re-skilling or the broader implications of AI on society.\n",
       "\n",
       "Overall, the writing quality is high in terms of clarity and ease of understanding, but it could benefit from improved conciseness in some areas.\n",
       "\n",
       "**Source_attribution**: The article does not accurately and comprehensively attribute information to reliable sources. The text makes several claims about the impact of AI on the job market, but fails to provide proper attribution to the original study or researchers mentioned in the context. For instance, it mentions that \"the study, done by some researchers with really long names, looks at something called \"large language models\" or LLMs,\" without providing any specific names or details from the original source. Additionally, the article makes claims about the impact of AI on different industries and job quality, which are not supported by the provided context. The lack of proper sourcing and attribution throughout the article indicates a significant gap in adhering to attribution standards. Therefore, the article does not meet the criteria for accurate and comprehensive attribution of information to reliable sources.\n",
       "\n",
       "**Objectivity**: The article presents information about the potential impact of AI on the job market, focusing on large language models (LLMs). However, it shows a significant bias in its reporting. The article primarily presents the perspective that AI will have a substantial impact on jobs, potentially displacing workers, and it does not adequately represent alternative viewpoints or address potential benefits of AI in the workplace.\n",
       "\n",
       "The language used is somewhat emotionally charged, with phrases like \"robot invasion\" and \"wake up tomorrow and find robots sitting at our desks,\" which could influence the reader's perception. The article also includes a personal anecdote about the author's experience with AI, which further detracts from its objectivity.\n",
       "\n",
       "While the article does mention that \"not everyone agrees about how big a deal this is going to be,\" it fails to provide specific examples of alternative viewpoints or credible sources that support a more balanced perspective. The discussion on potential benefits of AI, such as increased productivity or job creation in new fields, is largely absent.\n",
       "\n",
       "Overall, the article lacks the necessary balance and objectivity required for unbiased reporting on such a complex and multifaceted issue. It presents a one-sided view that could potentially mislead readers about the true nature and implications of AI's impact on the job market.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "for i in range(len(eval_inputs_batch)):\n",
    "    markdown_content = f\"\\n## Article {i+1}\\n\\n\"\n",
    "    markdown_content += \"| Metric | Score |\\n\"\n",
    "    markdown_content += \"|--------|-------|\\n\"\n",
    "    for metric, results in all_results.items():\n",
    "        score = results[i].score\n",
    "        markdown_content += f\"| {metric} | {score} |\\n\"\n",
    "\n",
    "    markdown_content += \"\\n### Feedback\\n\\n\"\n",
    "    for metric, results in all_results.items():\n",
    "        feedback = results[i].feedback\n",
    "        markdown_content += f\"**{metric.capitalize()}**: {feedback}\\n\\n\"\n",
    "\n",
    "    display(Markdown(markdown_content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
